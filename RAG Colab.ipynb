{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xhKeaMqMSbck"
      },
      "outputs": [],
      "source": [
        "!pip install langchain_google_vertexai langchain_community langgraph nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade google-auth google-auth-oauthlib google-api-python-client google.cloud"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TRisdTFZSg8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth login"
      ],
      "metadata": {
        "id": "GsxmmGllTAUb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project rag-model-448019"
      ],
      "metadata": {
        "id": "t9OCoubBTH8s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud projects add-iam-policy-binding rag-model-448019 \\\n",
        "    --member=\"serviceAccount:rag-model@rag-model-448019.iam.gserviceaccount.com\" \\\n",
        "    --role=\"roles/aiplatform.user\""
      ],
      "metadata": {
        "id": "c99ImPXaTSUT",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured unstructured[pdf] gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "3ijm0JFCTXJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your VertexAI credentials are configured\n",
        "import os\n",
        "import gradio as gr\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/content/rag-model-448019-fe37e29d6e38.json\"\n",
        "\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "from google.auth.transport.requests import Request\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    \"/content/rag-model-448019-fe37e29d6e38.json\",\n",
        "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"]\n",
        ")\n",
        "credentials.refresh(Request())"
      ],
      "metadata": {
        "id": "LEmkC42qTcTN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform as vertexai\n",
        "\n",
        "vertexai.init(\n",
        "    project=\"rag-model-448019\",  # Replace with your Google Cloud project ID\n",
        "    location=\"us-central1\",\n",
        "    credentials=credentials # Replace with your preferred region\n",
        ")"
      ],
      "metadata": {
        "id": "vMqiPkdoTwGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "llm = ChatVertexAI(model=\"gemini-1.5-pro-001\")"
      ],
      "metadata": {
        "id": "ek_C9kGnUEAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model=\"text-embedding-005\")"
      ],
      "metadata": {
        "id": "PldkVVNYUIOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "vector_store = InMemoryVectorStore(embeddings)\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "id": "WZQ3k3tOUNBh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_core.documents import Document\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langgraph.graph import START, StateGraph\n",
        "from typing_extensions import List, TypedDict\n",
        "import gradio as gr\n",
        "import os\n",
        "import shutil\n",
        "import time"
      ],
      "metadata": {
        "id": "WH-3WVByUQwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory to save uploaded files\n",
        "UPLOAD_DIRECTORY = \"/content/\"\n",
        "os.makedirs(UPLOAD_DIRECTORY, exist_ok=True)"
      ],
      "metadata": {
        "id": "HZvdGbzf0lNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_file(file):\n",
        "    try:\n",
        "        # Extract the base file name\n",
        "        base_filename = os.path.basename(file.name)\n",
        "        # Define the target file path\n",
        "        target_path = os.path.join(UPLOAD_DIRECTORY, base_filename)\n",
        "        # Copy the file to the target directory\n",
        "        shutil.copy(file.name, target_path)\n",
        "        DATA_PATH = \"/content/\"\n",
        "        # # Load and chunk contents of the documents\n",
        "        loader = DirectoryLoader(\n",
        "            DATA_PATH, glob=\"*.pdf\"\n",
        "        )\n",
        "        docs = loader.load()\n",
        "\n",
        "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "        all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Index chunks\n",
        "        _ = vector_store.add_documents(documents=all_splits)\n",
        "        return f\"File saved successfully\"\n",
        "    except Exception as e:\n",
        "        return f\"Error saving file: {str(e)}\"\n",
        "\n"
      ],
      "metadata": {
        "id": "EK7ScAW80zVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define prompt for question-answering\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "\n",
        "# Define state for application\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "# Define application steps\n",
        "def retrieve(state: State):\n",
        "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
        "    return {\"context\": retrieved_docs}\n",
        "\n",
        "\n",
        "def generate(state: State):\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
        "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
        "    response = llm.invoke(messages)\n",
        "    return {\"answer\": response.content}"
      ],
      "metadata": {
        "id": "wQFVQB-VMo-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile application and test\n",
        "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph = graph_builder.compile()"
      ],
      "metadata": {
        "id": "eKMwfQGUM2vq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_interface(question):\n",
        "    try:\n",
        "        response = graph.invoke({\"question\": question})\n",
        "        answer = response.get(\"answer\", \"No answer found.\")\n",
        "\n",
        "        return answer\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\", None"
      ],
      "metadata": {
        "id": "x30vJ9GQMkUF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    with gr.Tab(\"Upload Files\"):\n",
        "        upload_file = gr.File(label=\"Upload PDF File\")\n",
        "        upload_output = gr.Textbox(label=\"Upload Status\", interactive=False)\n",
        "        upload_button = gr.Button(\"Upload and Process\")\n",
        "\n",
        "    with gr.Tab(\"Ask Questions\"):\n",
        "        question_input = gr.Textbox(label=\"Ask a Question\")\n",
        "        answer_output = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "        question_button = gr.Button(\"Get Answer\")\n",
        "    upload_button.click(save_file, inputs=upload_file, outputs=upload_output)\n",
        "    question_button.click(chatbot_interface, inputs=question_input, outputs=answer_output)\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "vLolASVbUV9e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}